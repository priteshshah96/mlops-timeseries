{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151734dc72c8401989f6c9d64da1c5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()  # This will prompt for your token in the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f77117364b42ee84aaed2f8ec49564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "weather.parquet:   0%|          | 0.00/36.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c0230b460240a6ab4f263a67ba21bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather data saved successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0e19376ee7450fbcf5d923b6e11a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "demand.parquet:   0%|          | 0.00/1.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198d583e08964a2e8ff052dfa1b6ecab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d30cf4e49d49529909a87b00445fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demand data saved successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b28b404918c4cc4a05249df1a8ae533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "metadata.parquet:   0%|          | 0.00/202k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ea9dfcd5b54fc28d0732611da91d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata saved successfully\n",
      "weather.parquet: 34.61 MB\n",
      "demand.parquet: 987.38 MB\n",
      "metadata.parquet: 0.20 MB\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "\n",
    "try:\n",
    "    # Load and save weather data\n",
    "    weather_dataset = load_dataset(\"EDS-lab/electricity-demand\", 'weather')\n",
    "    df_weather = weather_dataset['train'].to_pandas()\n",
    "    df_weather.to_parquet('data/weather.parquet')\n",
    "    print(\"Weather data saved successfully\")\n",
    "    \n",
    "    # Load and save demand data\n",
    "    demand_dataset = load_dataset(\"EDS-lab/electricity-demand\", 'demand')\n",
    "    df_demand = demand_dataset['train'].to_pandas()\n",
    "    df_demand.to_parquet('data/demand.parquet')\n",
    "    print(\"Demand data saved successfully\")\n",
    "    \n",
    "    # Load and save metadata\n",
    "    metadata_dataset = load_dataset(\"EDS-lab/electricity-demand\", 'metadata')\n",
    "    df_metadata = metadata_dataset['train'].to_pandas()\n",
    "    df_metadata.to_parquet('data/metadata.parquet')\n",
    "    print(\"Metadata saved successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error saving data: {e}\")\n",
    "\n",
    "# Verify the files\n",
    "for file in ['weather.parquet', 'demand.parquet', 'metadata.parquet']:\n",
    "    path = os.path.join('data', file)\n",
    "    if os.path.exists(path):\n",
    "        size = os.path.getsize(path) / (1024 * 1024)  # Convert to MB\n",
    "        print(f\"{file}: {size:.2f} MB\")\n",
    "    else:\n",
    "        print(f\"{file} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing demand data (this may take a while)...\n",
      "Processed row group 1/227 (1,048,576 rows so far)...\n",
      "Processed row group 2/227 (2,097,152 rows so far)...\n",
      "Processed row group 3/227 (3,145,728 rows so far)...\n",
      "Processed row group 4/227 (4,194,304 rows so far)...\n",
      "Processed row group 5/227 (5,242,880 rows so far)...\n",
      "Processed row group 6/227 (6,291,456 rows so far)...\n",
      "Processed row group 7/227 (7,340,032 rows so far)...\n",
      "Processed row group 8/227 (8,388,608 rows so far)...\n",
      "Processed row group 9/227 (9,437,184 rows so far)...\n",
      "Processed row group 10/227 (10,485,760 rows so far)...\n",
      "Processed row group 11/227 (11,534,336 rows so far)...\n",
      "Processed row group 12/227 (12,582,912 rows so far)...\n",
      "Processed row group 13/227 (13,631,488 rows so far)...\n",
      "Processed row group 14/227 (14,680,064 rows so far)...\n",
      "Processed row group 15/227 (15,728,640 rows so far)...\n",
      "Processed row group 16/227 (16,777,216 rows so far)...\n",
      "Processed row group 17/227 (17,825,792 rows so far)...\n",
      "Processed row group 18/227 (18,874,368 rows so far)...\n",
      "Processed row group 19/227 (19,922,944 rows so far)...\n",
      "Processed row group 20/227 (20,971,520 rows so far)...\n",
      "Processed row group 21/227 (22,020,096 rows so far)...\n",
      "Processed row group 22/227 (23,068,672 rows so far)...\n",
      "Processed row group 23/227 (24,117,248 rows so far)...\n",
      "Processed row group 24/227 (25,165,824 rows so far)...\n",
      "Processed row group 25/227 (26,214,400 rows so far)...\n",
      "Processed row group 26/227 (27,262,976 rows so far)...\n",
      "Processed row group 27/227 (28,311,552 rows so far)...\n",
      "Processed row group 28/227 (29,360,128 rows so far)...\n",
      "Processed row group 29/227 (30,408,704 rows so far)...\n",
      "Processed row group 30/227 (31,457,280 rows so far)...\n",
      "Processed row group 31/227 (32,505,856 rows so far)...\n",
      "Processed row group 32/227 (33,554,432 rows so far)...\n",
      "Processed row group 33/227 (34,603,008 rows so far)...\n",
      "Processed row group 34/227 (35,651,584 rows so far)...\n",
      "Processed row group 35/227 (36,700,160 rows so far)...\n",
      "Processed row group 36/227 (37,748,736 rows so far)...\n",
      "Processed row group 37/227 (38,797,312 rows so far)...\n",
      "Processed row group 38/227 (39,845,888 rows so far)...\n",
      "Processed row group 39/227 (40,894,464 rows so far)...\n",
      "Processed row group 40/227 (41,943,040 rows so far)...\n",
      "Processed row group 41/227 (42,991,616 rows so far)...\n",
      "Processed row group 42/227 (44,040,192 rows so far)...\n",
      "Processed row group 43/227 (45,088,768 rows so far)...\n",
      "Processed row group 44/227 (46,137,344 rows so far)...\n",
      "Processed row group 45/227 (47,185,920 rows so far)...\n",
      "Processed row group 46/227 (48,234,496 rows so far)...\n",
      "Processed row group 47/227 (49,283,072 rows so far)...\n",
      "Processed row group 48/227 (50,331,648 rows so far)...\n",
      "Processed row group 49/227 (51,380,224 rows so far)...\n",
      "Processed row group 50/227 (52,428,800 rows so far)...\n",
      "Processed row group 51/227 (53,477,376 rows so far)...\n",
      "Processed row group 52/227 (54,525,952 rows so far)...\n",
      "Processed row group 53/227 (55,574,528 rows so far)...\n",
      "Processed row group 54/227 (56,623,104 rows so far)...\n",
      "Processed row group 55/227 (57,671,680 rows so far)...\n",
      "Processed row group 56/227 (58,720,256 rows so far)...\n",
      "Processed row group 57/227 (59,768,832 rows so far)...\n",
      "Processed row group 58/227 (60,817,408 rows so far)...\n",
      "Processed row group 59/227 (61,865,984 rows so far)...\n",
      "Processed row group 60/227 (62,914,560 rows so far)...\n",
      "Processed row group 61/227 (63,963,136 rows so far)...\n",
      "Processed row group 62/227 (65,011,712 rows so far)...\n",
      "Processed row group 63/227 (66,060,288 rows so far)...\n",
      "Processed row group 64/227 (67,108,864 rows so far)...\n",
      "Processed row group 65/227 (68,157,440 rows so far)...\n",
      "Processed row group 66/227 (69,206,016 rows so far)...\n",
      "Processed row group 67/227 (70,254,592 rows so far)...\n",
      "Processed row group 68/227 (71,303,168 rows so far)...\n",
      "Processed row group 69/227 (72,351,744 rows so far)...\n",
      "Processed row group 70/227 (73,400,320 rows so far)...\n",
      "Processed row group 71/227 (74,448,896 rows so far)...\n",
      "Processed row group 72/227 (75,497,472 rows so far)...\n",
      "Processed row group 73/227 (76,546,048 rows so far)...\n",
      "Processed row group 74/227 (77,594,624 rows so far)...\n",
      "Processed row group 75/227 (78,643,200 rows so far)...\n",
      "Processed row group 76/227 (79,691,776 rows so far)...\n",
      "Processed row group 77/227 (80,740,352 rows so far)...\n",
      "Processed row group 78/227 (81,788,928 rows so far)...\n",
      "Processed row group 79/227 (82,837,504 rows so far)...\n",
      "Processed row group 80/227 (83,886,080 rows so far)...\n",
      "Processed row group 81/227 (84,934,656 rows so far)...\n",
      "Processed row group 82/227 (85,983,232 rows so far)...\n",
      "Processed row group 83/227 (87,031,808 rows so far)...\n",
      "Processed row group 84/227 (88,080,384 rows so far)...\n",
      "Processed row group 85/227 (89,128,960 rows so far)...\n",
      "Processed row group 86/227 (90,177,536 rows so far)...\n",
      "Processed row group 87/227 (91,226,112 rows so far)...\n",
      "Processed row group 88/227 (92,274,688 rows so far)...\n",
      "Processed row group 89/227 (93,323,264 rows so far)...\n",
      "Processed row group 90/227 (94,371,840 rows so far)...\n",
      "Processed row group 91/227 (95,420,416 rows so far)...\n",
      "Processed row group 92/227 (96,468,992 rows so far)...\n",
      "Processed row group 93/227 (97,517,568 rows so far)...\n",
      "Processed row group 94/227 (98,566,144 rows so far)...\n",
      "Processed row group 95/227 (99,614,720 rows so far)...\n",
      "Processed row group 96/227 (100,663,296 rows so far)...\n",
      "Processed row group 97/227 (101,711,872 rows so far)...\n",
      "Processed row group 98/227 (102,760,448 rows so far)...\n",
      "Processed row group 99/227 (103,809,024 rows so far)...\n",
      "Processed row group 100/227 (104,857,600 rows so far)...\n",
      "Processed row group 101/227 (105,906,176 rows so far)...\n",
      "Processed row group 102/227 (106,954,752 rows so far)...\n",
      "Processed row group 103/227 (108,003,328 rows so far)...\n",
      "Processed row group 104/227 (109,051,904 rows so far)...\n",
      "Processed row group 105/227 (110,100,480 rows so far)...\n",
      "Processed row group 106/227 (111,149,056 rows so far)...\n",
      "Processed row group 107/227 (112,197,632 rows so far)...\n",
      "Processed row group 108/227 (113,246,208 rows so far)...\n",
      "Processed row group 109/227 (114,294,784 rows so far)...\n",
      "Processed row group 110/227 (115,343,360 rows so far)...\n",
      "Processed row group 111/227 (116,391,936 rows so far)...\n",
      "Processed row group 112/227 (117,440,512 rows so far)...\n",
      "Processed row group 113/227 (118,489,088 rows so far)...\n",
      "Processed row group 114/227 (119,537,664 rows so far)...\n",
      "Processed row group 115/227 (120,586,240 rows so far)...\n",
      "Processed row group 116/227 (121,634,816 rows so far)...\n",
      "Processed row group 117/227 (122,683,392 rows so far)...\n",
      "Processed row group 118/227 (123,731,968 rows so far)...\n",
      "Processed row group 119/227 (124,780,544 rows so far)...\n",
      "Processed row group 120/227 (125,829,120 rows so far)...\n",
      "Processed row group 121/227 (126,877,696 rows so far)...\n",
      "Processed row group 122/227 (127,926,272 rows so far)...\n",
      "Processed row group 123/227 (128,974,848 rows so far)...\n",
      "Processed row group 124/227 (130,023,424 rows so far)...\n",
      "Processed row group 125/227 (131,072,000 rows so far)...\n",
      "Processed row group 126/227 (132,120,576 rows so far)...\n",
      "Processed row group 127/227 (133,169,152 rows so far)...\n",
      "Processed row group 128/227 (134,217,728 rows so far)...\n",
      "Processed row group 129/227 (135,266,304 rows so far)...\n",
      "Processed row group 130/227 (136,314,880 rows so far)...\n",
      "Processed row group 131/227 (137,363,456 rows so far)...\n",
      "Processed row group 132/227 (138,412,032 rows so far)...\n",
      "Processed row group 133/227 (139,460,608 rows so far)...\n",
      "Processed row group 134/227 (140,509,184 rows so far)...\n",
      "Processed row group 135/227 (141,557,760 rows so far)...\n",
      "Processed row group 136/227 (142,606,336 rows so far)...\n",
      "Processed row group 137/227 (143,654,912 rows so far)...\n",
      "Processed row group 138/227 (144,703,488 rows so far)...\n",
      "Processed row group 139/227 (145,752,064 rows so far)...\n",
      "Processed row group 140/227 (146,800,640 rows so far)...\n",
      "Processed row group 141/227 (147,849,216 rows so far)...\n",
      "Processed row group 142/227 (148,897,792 rows so far)...\n",
      "Processed row group 143/227 (149,946,368 rows so far)...\n",
      "Processed row group 144/227 (150,994,944 rows so far)...\n",
      "Processed row group 145/227 (152,043,520 rows so far)...\n",
      "Processed row group 146/227 (153,092,096 rows so far)...\n",
      "Processed row group 147/227 (154,140,672 rows so far)...\n",
      "Processed row group 148/227 (155,189,248 rows so far)...\n",
      "Processed row group 149/227 (156,237,824 rows so far)...\n",
      "Processed row group 150/227 (157,286,400 rows so far)...\n",
      "Processed row group 151/227 (158,334,976 rows so far)...\n",
      "Processed row group 152/227 (159,383,552 rows so far)...\n",
      "Processed row group 153/227 (160,432,128 rows so far)...\n",
      "Processed row group 154/227 (161,480,704 rows so far)...\n",
      "Processed row group 155/227 (162,529,280 rows so far)...\n",
      "Processed row group 156/227 (163,577,856 rows so far)...\n",
      "Processed row group 157/227 (164,626,432 rows so far)...\n",
      "Processed row group 158/227 (165,675,008 rows so far)...\n",
      "Processed row group 159/227 (166,723,584 rows so far)...\n",
      "Processed row group 160/227 (167,772,160 rows so far)...\n",
      "Processed row group 161/227 (168,820,736 rows so far)...\n",
      "Processed row group 162/227 (169,869,312 rows so far)...\n",
      "Processed row group 163/227 (170,917,888 rows so far)...\n",
      "Processed row group 164/227 (171,966,464 rows so far)...\n",
      "Processed row group 165/227 (173,015,040 rows so far)...\n",
      "Processed row group 166/227 (174,063,616 rows so far)...\n",
      "Processed row group 167/227 (175,112,192 rows so far)...\n",
      "Processed row group 168/227 (176,160,768 rows so far)...\n",
      "Processed row group 169/227 (177,209,344 rows so far)...\n",
      "Processed row group 170/227 (178,257,920 rows so far)...\n",
      "Processed row group 171/227 (179,306,496 rows so far)...\n",
      "Processed row group 172/227 (180,355,072 rows so far)...\n",
      "Processed row group 173/227 (181,403,648 rows so far)...\n",
      "Processed row group 174/227 (182,452,224 rows so far)...\n",
      "Processed row group 175/227 (183,500,800 rows so far)...\n",
      "Processed row group 176/227 (184,549,376 rows so far)...\n",
      "Processed row group 177/227 (185,597,952 rows so far)...\n",
      "Processed row group 178/227 (186,646,528 rows so far)...\n",
      "Processed row group 179/227 (187,695,104 rows so far)...\n",
      "Processed row group 180/227 (188,743,680 rows so far)...\n",
      "Processed row group 181/227 (189,792,256 rows so far)...\n",
      "Processed row group 182/227 (190,840,832 rows so far)...\n",
      "Processed row group 183/227 (191,889,408 rows so far)...\n",
      "Processed row group 184/227 (192,937,984 rows so far)...\n",
      "Processed row group 185/227 (193,986,560 rows so far)...\n",
      "Processed row group 186/227 (195,035,136 rows so far)...\n",
      "Processed row group 187/227 (196,083,712 rows so far)...\n",
      "Processed row group 188/227 (197,132,288 rows so far)...\n",
      "Processed row group 189/227 (198,180,864 rows so far)...\n",
      "Processed row group 190/227 (199,229,440 rows so far)...\n",
      "Processed row group 191/227 (200,278,016 rows so far)...\n",
      "Processed row group 192/227 (201,326,592 rows so far)...\n",
      "Processed row group 193/227 (202,375,168 rows so far)...\n",
      "Processed row group 194/227 (203,423,744 rows so far)...\n",
      "Processed row group 195/227 (204,472,320 rows so far)...\n",
      "Processed row group 196/227 (205,520,896 rows so far)...\n",
      "Processed row group 197/227 (206,569,472 rows so far)...\n",
      "Processed row group 198/227 (207,618,048 rows so far)...\n",
      "Processed row group 199/227 (208,666,624 rows so far)...\n",
      "Processed row group 200/227 (209,715,200 rows so far)...\n",
      "Processed row group 201/227 (210,763,776 rows so far)...\n",
      "Processed row group 202/227 (211,812,352 rows so far)...\n",
      "Processed row group 203/227 (212,860,928 rows so far)...\n",
      "Processed row group 204/227 (213,909,504 rows so far)...\n",
      "Processed row group 205/227 (214,958,080 rows so far)...\n",
      "Processed row group 206/227 (216,006,656 rows so far)...\n",
      "Processed row group 207/227 (217,055,232 rows so far)...\n",
      "Processed row group 208/227 (218,103,808 rows so far)...\n",
      "Processed row group 209/227 (219,152,384 rows so far)...\n",
      "Processed row group 210/227 (220,200,960 rows so far)...\n",
      "Processed row group 211/227 (221,249,536 rows so far)...\n",
      "Processed row group 212/227 (222,298,112 rows so far)...\n",
      "Processed row group 213/227 (223,346,688 rows so far)...\n",
      "Processed row group 214/227 (224,395,264 rows so far)...\n",
      "Processed row group 215/227 (225,443,840 rows so far)...\n",
      "Processed row group 216/227 (226,492,416 rows so far)...\n",
      "Processed row group 217/227 (227,540,992 rows so far)...\n",
      "Processed row group 218/227 (228,589,568 rows so far)...\n",
      "Processed row group 219/227 (229,638,144 rows so far)...\n",
      "Processed row group 220/227 (230,686,720 rows so far)...\n",
      "Processed row group 221/227 (231,735,296 rows so far)...\n",
      "Processed row group 222/227 (232,783,872 rows so far)...\n",
      "Processed row group 223/227 (233,832,448 rows so far)...\n",
      "Processed row group 224/227 (234,881,024 rows so far)...\n",
      "Processed row group 225/227 (235,929,600 rows so far)...\n",
      "Processed row group 226/227 (236,978,176 rows so far)...\n",
      "Processed row group 227/227 (237,944,171 rows so far)...\n",
      "\n",
      "Demand Data Analysis:\n",
      "-------------------\n",
      "Total records: 237,944,171\n",
      "Number of unique buildings/meters: 7,514\n",
      "Date range: 2011-01-01 00:30:00 to 2017-12-31 23:00:00\n",
      "\n",
      "Electricity demand statistics:\n",
      "Mean: 44.32\n",
      "Std Dev: 391.72\n",
      "Min: 0.00\n",
      "Max: 221228.00\n",
      "\n",
      "Metadata Analysis:\n",
      "-----------------\n",
      "Total buildings: 7572\n",
      "\n",
      "Columns available:\n",
      "['unique_id', 'dataset', 'building_id', 'location_id', 'latitude', 'longitude', 'location', 'timezone', 'building_class', 'cluster_size', 'freq']\n",
      "\n",
      "Building class distribution:\n",
      "building_class\n",
      "Residential    5936\n",
      "Commercial     1636\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Weather Data Analysis (Sample):\n",
      "-----------------------------\n",
      "Sample size: 1,000 records\n",
      "Total row groups: 1\n",
      "\n",
      "Columns available:\n",
      "['timestamp', 'temperature_2m', 'relative_humidity_2m', 'dew_point_2m', 'apparent_temperature', 'precipitation', 'rain', 'snowfall', 'snow_depth', 'weather_code', 'pressure_msl', 'surface_pressure', 'cloud_cover', 'cloud_cover_low', 'cloud_cover_mid', 'cloud_cover_high', 'et0_fao_evapotranspiration', 'vapour_pressure_deficit', 'wind_speed_10m', 'wind_direction_10m', 'wind_gusts_10m', 'soil_temperature_0_to_7cm', 'soil_temperature_7_to_28cm', 'soil_moisture_0_to_7cm', 'soil_moisture_7_to_28cm', 'is_day', 'sunshine_duration', 'shortwave_radiation', 'direct_radiation', 'diffuse_radiation', 'direct_normal_irradiance', 'terrestrial_radiation', 'location_id']\n",
      "\n",
      "Numeric columns summary:\n",
      "\n",
      "temperature_2m:\n",
      "count    1000.000000\n",
      "mean        4.943850\n",
      "std         3.725788\n",
      "min        -3.023500\n",
      "25%         1.876500\n",
      "50%         4.926500\n",
      "75%         8.176500\n",
      "max        11.876500\n",
      "Name: temperature_2m, dtype: float64\n",
      "\n",
      "relative_humidity_2m:\n",
      "count    1000.000000\n",
      "mean       88.064270\n",
      "std         8.021030\n",
      "min        59.143436\n",
      "25%        82.734978\n",
      "50%        90.132381\n",
      "75%        94.324564\n",
      "max        99.662613\n",
      "Name: relative_humidity_2m, dtype: float64\n",
      "\n",
      "dew_point_2m:\n",
      "count    1000.000000\n",
      "mean        3.076500\n",
      "std         3.901097\n",
      "min        -6.023500\n",
      "25%        -0.036000\n",
      "50%         3.101500\n",
      "75%         6.376500\n",
      "max        10.726501\n",
      "Name: dew_point_2m, dtype: float64\n",
      "\n",
      "apparent_temperature:\n",
      "count    1000.000000\n",
      "mean        0.998088\n",
      "std         3.817998\n",
      "min        -7.361339\n",
      "25%        -1.818583\n",
      "50%         1.015687\n",
      "75%         4.031168\n",
      "max         9.276735\n",
      "Name: apparent_temperature, dtype: float64\n",
      "\n",
      "precipitation:\n",
      "count    1000.000000\n",
      "mean        0.082600\n",
      "std         0.324288\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.000000\n",
      "max         4.000000\n",
      "Name: precipitation, dtype: float64\n",
      "\n",
      "rain:\n",
      "count    1000.000000\n",
      "mean        0.081100\n",
      "std         0.319586\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.000000\n",
      "max         4.000000\n",
      "Name: rain, dtype: float64\n",
      "\n",
      "snowfall:\n",
      "count    1000.000000\n",
      "mean        0.001050\n",
      "std         0.015147\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.000000\n",
      "max         0.350000\n",
      "Name: snowfall, dtype: float64\n",
      "\n",
      "snow_depth:\n",
      "count    1000.000000\n",
      "mean        0.000220\n",
      "std         0.001468\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.000000\n",
      "max         0.010000\n",
      "Name: snow_depth, dtype: float64\n",
      "\n",
      "weather_code:\n",
      "count    1000.000000\n",
      "mean        8.775000\n",
      "std        17.283087\n",
      "min         0.000000\n",
      "25%         2.000000\n",
      "50%         3.000000\n",
      "75%         3.000000\n",
      "max        73.000000\n",
      "Name: weather_code, dtype: float64\n",
      "\n",
      "pressure_msl:\n",
      "count    1000.000000\n",
      "mean     1018.881958\n",
      "std        10.764836\n",
      "min       988.099976\n",
      "25%      1011.574982\n",
      "50%      1019.299988\n",
      "75%      1025.400024\n",
      "max      1040.199951\n",
      "Name: pressure_msl, dtype: float64\n",
      "\n",
      "surface_pressure:\n",
      "count    1000.000000\n",
      "mean     1013.639893\n",
      "std        10.682716\n",
      "min       983.084595\n",
      "25%      1006.471588\n",
      "50%      1014.102386\n",
      "75%      1020.117630\n",
      "max      1034.736572\n",
      "Name: surface_pressure, dtype: float64\n",
      "\n",
      "cloud_cover:\n",
      "count    1000.000000\n",
      "mean       77.879410\n",
      "std        30.545351\n",
      "min         0.000000\n",
      "25%        63.900001\n",
      "50%        92.699997\n",
      "75%       100.000000\n",
      "max       100.000000\n",
      "Name: cloud_cover, dtype: float64\n",
      "\n",
      "cloud_cover_low:\n",
      "count    1000.000000\n",
      "mean       72.447998\n",
      "std        34.125206\n",
      "min         0.000000\n",
      "25%        52.000000\n",
      "50%        89.000000\n",
      "75%       100.000000\n",
      "max       100.000000\n",
      "Name: cloud_cover_low, dtype: float64\n",
      "\n",
      "cloud_cover_mid:\n",
      "count    1000.000000\n",
      "mean       28.363001\n",
      "std        35.942413\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         7.000000\n",
      "75%        57.000000\n",
      "max       100.000000\n",
      "Name: cloud_cover_mid, dtype: float64\n",
      "\n",
      "cloud_cover_high:\n",
      "count    1000.000000\n",
      "mean       37.235001\n",
      "std        41.101864\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%        13.000000\n",
      "75%        84.000000\n",
      "max       100.000000\n",
      "Name: cloud_cover_high, dtype: float64\n",
      "\n",
      "et0_fao_evapotranspiration:\n",
      "count    1000.000000\n",
      "mean        0.020566\n",
      "std         0.025912\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.009352\n",
      "75%         0.033281\n",
      "max         0.149048\n",
      "Name: et0_fao_evapotranspiration, dtype: float64\n",
      "\n",
      "vapour_pressure_deficit:\n",
      "count    1000.000000\n",
      "mean        0.107327\n",
      "std         0.077379\n",
      "min         0.002385\n",
      "25%         0.046100\n",
      "50%         0.087655\n",
      "75%         0.157460\n",
      "max         0.409911\n",
      "Name: vapour_pressure_deficit, dtype: float64\n",
      "\n",
      "wind_speed_10m:\n",
      "count    1000.000000\n",
      "mean       16.692636\n",
      "std         7.880153\n",
      "min         0.360000\n",
      "25%        10.619984\n",
      "50%        15.503005\n",
      "75%        21.408652\n",
      "max        42.853611\n",
      "Name: wind_speed_10m, dtype: float64\n",
      "\n",
      "wind_direction_10m:\n",
      "count    1000.000000\n",
      "mean      199.174606\n",
      "std       101.782471\n",
      "min         1.193471\n",
      "25%       157.137089\n",
      "50%       220.747765\n",
      "75%       256.931923\n",
      "max       360.000000\n",
      "Name: wind_direction_10m, dtype: float64\n",
      "\n",
      "wind_gusts_10m:\n",
      "count    1000.000000\n",
      "mean       33.130436\n",
      "std        15.417267\n",
      "min         3.600000\n",
      "25%        20.880001\n",
      "50%        31.319998\n",
      "75%        42.839996\n",
      "max        70.919998\n",
      "Name: wind_gusts_10m, dtype: float64\n",
      "\n",
      "soil_temperature_0_to_7cm:\n",
      "count    1000.000000\n",
      "mean        4.307250\n",
      "std         2.773841\n",
      "min        -0.123500\n",
      "25%         2.064000\n",
      "50%         3.926500\n",
      "75%         6.626500\n",
      "max         9.476501\n",
      "Name: soil_temperature_0_to_7cm, dtype: float64\n",
      "\n",
      "soil_temperature_7_to_28cm:\n",
      "count    1000.000000\n",
      "mean        4.319150\n",
      "std         2.036583\n",
      "min         0.876500\n",
      "25%         2.626500\n",
      "50%         3.976500\n",
      "75%         6.126500\n",
      "max         8.026500\n",
      "Name: soil_temperature_7_to_28cm, dtype: float64\n",
      "\n",
      "soil_moisture_0_to_7cm:\n",
      "count    1000.000000\n",
      "mean        0.392869\n",
      "std         0.016865\n",
      "min         0.362000\n",
      "25%         0.381000\n",
      "50%         0.392000\n",
      "75%         0.404000\n",
      "max         0.430000\n",
      "Name: soil_moisture_0_to_7cm, dtype: float64\n",
      "\n",
      "soil_moisture_7_to_28cm:\n",
      "count    1000.000000\n",
      "mean        0.394999\n",
      "std         0.014951\n",
      "min         0.369000\n",
      "25%         0.384000\n",
      "50%         0.393000\n",
      "75%         0.407000\n",
      "max         0.430000\n",
      "Name: soil_moisture_7_to_28cm, dtype: float64\n",
      "\n",
      "is_day:\n",
      "count    1000.000000\n",
      "mean        0.367000\n",
      "std         0.482228\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         1.000000\n",
      "max         1.000000\n",
      "Name: is_day, dtype: float64\n",
      "\n",
      "sunshine_duration:\n",
      "count    1000.000000\n",
      "mean      381.331970\n",
      "std      1026.434082\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.000000\n",
      "max      3600.000000\n",
      "Name: sunshine_duration, dtype: float64\n",
      "\n",
      "shortwave_radiation:\n",
      "count    1000.000000\n",
      "mean       30.388000\n",
      "std        60.608902\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%        30.000000\n",
      "max       374.000000\n",
      "Name: shortwave_radiation, dtype: float64\n",
      "\n",
      "direct_radiation:\n",
      "count    1000.000000\n",
      "mean       10.855000\n",
      "std        33.545719\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         1.000000\n",
      "max       279.000000\n",
      "Name: direct_radiation, dtype: float64\n",
      "\n",
      "diffuse_radiation:\n",
      "count    1000.000000\n",
      "mean       19.533001\n",
      "std        34.488552\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%        26.000000\n",
      "max       180.000000\n",
      "Name: diffuse_radiation, dtype: float64\n",
      "\n",
      "direct_normal_irradiance:\n",
      "count    1000.000000\n",
      "mean       42.639774\n",
      "std       118.303078\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         5.874740\n",
      "max       763.300293\n",
      "Name: direct_normal_irradiance, dtype: float64\n",
      "\n",
      "terrestrial_radiation:\n",
      "count    1000.000000\n",
      "mean      108.535141\n",
      "std       169.041977\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%       219.222923\n",
      "max       577.496033\n",
      "Name: terrestrial_radiation, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "def analyze_demand_stats(file_path, batch_size=10000):\n",
    "    \"\"\"\n",
    "    Analyze demand data using pyarrow's batched reading\n",
    "    \"\"\"\n",
    "    # Initialize statistics\n",
    "    total_rows = 0\n",
    "    value_sum = 0\n",
    "    value_sq_sum = 0\n",
    "    min_val = float('inf')\n",
    "    max_val = float('-inf')\n",
    "    min_date = None\n",
    "    max_date = None\n",
    "    unique_ids = set()\n",
    "    \n",
    "    # Open the parquet file\n",
    "    parquet_file = pq.ParquetFile(file_path)\n",
    "    num_row_groups = parquet_file.num_row_groups\n",
    "    \n",
    "    # Process each row group\n",
    "    for i in range(num_row_groups):\n",
    "        # Read one row group at a time\n",
    "        row_group = parquet_file.read_row_group(i, columns=['timestamp', 'y', 'unique_id'])\n",
    "        df_chunk = row_group.to_pandas()\n",
    "        \n",
    "        # Process in smaller batches\n",
    "        for start_idx in range(0, len(df_chunk), batch_size):\n",
    "            end_idx = min(start_idx + batch_size, len(df_chunk))\n",
    "            batch = df_chunk.iloc[start_idx:end_idx]\n",
    "            \n",
    "            # Update statistics\n",
    "            total_rows += len(batch)\n",
    "            value_sum += batch['y'].sum()\n",
    "            value_sq_sum += (batch['y']**2).sum()\n",
    "            min_val = min(min_val, batch['y'].min())\n",
    "            max_val = max(max_val, batch['y'].max())\n",
    "            \n",
    "            # Update date range\n",
    "            batch_min_date = batch['timestamp'].min()\n",
    "            batch_max_date = batch['timestamp'].max()\n",
    "            min_date = batch_min_date if min_date is None else min(min_date, batch_min_date)\n",
    "            max_date = batch_max_date if max_date is None else max(max_date, batch_max_date)\n",
    "            \n",
    "            # Update unique IDs\n",
    "            unique_ids.update(batch['unique_id'].unique())\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Processed row group {i+1}/{num_row_groups} ({total_rows:,} rows so far)...\")\n",
    "    \n",
    "    # Calculate final statistics\n",
    "    mean = value_sum / total_rows\n",
    "    variance = (value_sq_sum / total_rows) - (mean ** 2)\n",
    "    std = np.sqrt(variance)\n",
    "    \n",
    "    return {\n",
    "        'total_rows': total_rows,\n",
    "        'mean': mean,\n",
    "        'std': std,\n",
    "        'min': min_val,\n",
    "        'max': max_val,\n",
    "        'date_range': (min_date, max_date),\n",
    "        'num_unique_ids': len(unique_ids)\n",
    "    }\n",
    "\n",
    "def analyze_metadata(metadata_path):\n",
    "    \"\"\"\n",
    "    Analyze the metadata file (which is small enough to load entirely)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        metadata_df = pd.read_parquet(metadata_path)\n",
    "        print(\"\\nMetadata Analysis:\")\n",
    "        print(\"-----------------\")\n",
    "        print(f\"Total buildings: {len(metadata_df)}\")\n",
    "        print(\"\\nColumns available:\")\n",
    "        print(metadata_df.columns.tolist())\n",
    "        \n",
    "        if 'building_class' in metadata_df.columns:\n",
    "            print(\"\\nBuilding class distribution:\")\n",
    "            print(metadata_df['building_class'].value_counts())\n",
    "        \n",
    "        return metadata_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading metadata: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_weather_sample(weather_path, sample_rows=1000):\n",
    "    \"\"\"\n",
    "    Analyze a sample of weather data using row groups\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parquet_file = pq.ParquetFile(weather_path)\n",
    "        \n",
    "        # Read the first row group\n",
    "        first_group = parquet_file.read_row_group(0)\n",
    "        weather_sample = first_group.to_pandas().head(sample_rows)\n",
    "        \n",
    "        print(\"\\nWeather Data Analysis (Sample):\")\n",
    "        print(\"-----------------------------\")\n",
    "        print(f\"Sample size: {len(weather_sample):,} records\")\n",
    "        print(f\"Total row groups: {parquet_file.num_row_groups}\")\n",
    "        print(\"\\nColumns available:\")\n",
    "        print(weather_sample.columns.tolist())\n",
    "        \n",
    "        print(\"\\nNumeric columns summary:\")\n",
    "        numeric_cols = weather_sample.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_cols:\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(weather_sample[col].describe())\n",
    "        \n",
    "        return weather_sample\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading weather data: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Set up paths\n",
    "data_path = os.path.join('..', 'data')\n",
    "demand_path = os.path.join(data_path, 'demand.parquet')\n",
    "weather_path = os.path.join(data_path, 'weather.parquet')\n",
    "metadata_path = os.path.join(data_path, 'metadata.parquet')\n",
    "\n",
    "# Run analyses\n",
    "print(\"Analyzing demand data (this may take a while)...\")\n",
    "try:\n",
    "    demand_stats = analyze_demand_stats(demand_path)\n",
    "    \n",
    "    print(\"\\nDemand Data Analysis:\")\n",
    "    print(\"-------------------\")\n",
    "    print(f\"Total records: {demand_stats['total_rows']:,}\")\n",
    "    print(f\"Number of unique buildings/meters: {demand_stats['num_unique_ids']:,}\")\n",
    "    print(f\"Date range: {demand_stats['date_range'][0]} to {demand_stats['date_range'][1]}\")\n",
    "    print(\"\\nElectricity demand statistics:\")\n",
    "    print(f\"Mean: {demand_stats['mean']:.2f}\")\n",
    "    print(f\"Std Dev: {demand_stats['std']:.2f}\")\n",
    "    print(f\"Min: {demand_stats['min']:.2f}\")\n",
    "    print(f\"Max: {demand_stats['max']:.2f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error analyzing demand data: {str(e)}\")\n",
    "\n",
    "# Analyze metadata\n",
    "metadata_df = analyze_metadata(metadata_path)\n",
    "\n",
    "# Analyze weather data sample\n",
    "weather_sample = analyze_weather_sample(weather_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
